data:
  path: null
  max_length: null
  batch_size: 128

actor:
  model_name: null
  use_liger_kernel: false
  gradient_checkpointing: true
  ddp_size: 1
  tp_size: 1
  sp_size: 1
  max_length_per_device: null
  beta: 0.1
  lr: 5e-7
  weight_decay: 1e-2
  max_grad_norm: 1.0
  scheduler: cosine
  warmup_ratio: 0.1
  offload_optimizer: true

  lora:
    use_lora: false
    r: 16
    lora_alpha: 32
    lora_dropout: 0.05
    use_rslora: false
    target_modules:
      - q_proj
      - v_proj
      - k_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj
    modules_to_save: null

ref_actor:
  model_name: ${actor.model_name}
  use_liger_kernel: ${actor.use_liger_kernel}
  ddp_size: ${actor.ddp_size}
  tp_size: ${actor.tp_size}
  sp_size: ${actor.sp_size}
  max_inference_length_per_device: ${actor.max_length_per_device}
  offload_model: false

trainer:
  project: null
  experiment_name: null
  load_ckpt_from: null
  n_epochs: 1
  save_dir: ckpts/${trainer.experiment_name}
  save_freq: null
  use_wandb: true