FROM slimerl/slime:latest

RUN pip install math_verify hydra-core ninja torchdata

RUN git clone https://github.com/Dao-AILab/flash-attention.git && \
    cd flash-attention/ && \
    git checkout 3ba6f82 && \
    git submodule update --init && \
    cd hopper/ && \
    python setup.py install && \
    python_path=$(python -c "import site; print(site.getsitepackages()[0])") && \
    mkdir -p $python_path/flash_attn_3 && \
    cp flash_attn_interface.py $python_path/flash_attn_3/flash_attn_interface.py